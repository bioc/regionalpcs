---
title: "regionalpcs"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{regionalpcs}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  echo = TRUE
)
```

# regionalpcs

The goal of *regionalpcs* is to provide functions to easily summarize DNA methylation data on a regional level using regional principal components (rPCs). The rPCs help to capture more biologically-relevant signals for downstream analyses.


# `regionalpcs` R Package Tutorial 

## Loading packages
To begin working with the *regionalpcs* R package, we need to first load it into our R session along with some other necessary packages. We can do this using the **`library()`** function in R. Here's an example code snippet to load the required packages:

```{r setup, message=FALSE, warning=FALSE}
library(regionalpcs)
library(RNOmni)
library(GenomicRanges)
library(IlluminaHumanMethylation450kanno.ilmn12.hg19)
library(liftOver)
library(tidyverse)
```

Here, we load the *regionalpcs* package, which is the main package we'll be using in this tutorial. We also load *RNOmni*, which provides normalization functions, *GenomicRanges*, which provides tools for working with genomic intervals, and *tidyverse*, which provides a suite of tools for data manipulation and visualization.

It's important to note that you need to have these packages installed on your machine before loading them. You can install them using the **`install.packages()`** function in R.

Once the packages are loaded, we can start using the functions provided by each package.


## Loading in a dataset

In this section, we'll load a methylation dataset collected from TCGA using 450k methylation arrays. Before we can start any analysis, we need to load in the data and take a look at what we're working with.

The **`betas`** dataset included with the `regionalpcs` package contains methylation values for 293 methylation sites and 300 individuals. We've subset the original dataset to save space and compute time for this vignette. To work well for downstream statistical analyses, we'll need to normalize the beta values by removing low variance CpGs and applying the inverse normal transform.


```{r view_data}
head(betas)[1:3]
dim(betas)
```

We can see that the row names contain CpG IDs and positions, while the columns contain methylation beta values, which range from 0 to 1.

## Getting methylation array probe positions

In methylation array data, we may have only the probe ID without a position. To obtain the probe position, we can use Illumina annotations for the 450k methylation arrays found in the *IlluminaHumanMethylation450kanno.ilmn12.hg19* R package. In this example, we will extract the probe names from our betas data frame and separate the probe name from the CpG position using regex to find the last underscore.

```{r}
# get the probe names from the betas data frame
cpg_df <- data.frame(cpgs=rownames(betas)) %>%
  # separate the probe name from the cpg position using regex to find the last underscore
  separate(cpgs, into=c('cpg_pos', 'probe'), sep= "_(?=[^_]+$)", extra='merge')
head(cpg_df)

# load the Illumina 450k array probe positions
data(Locations)
probe_positions=data.frame(Locations)
head(probe_positions)

# attach probe positions to our cpg data frame
# format the data frame first
formatted_probe_positions <- probe_positions %>%
  rownames_to_column('probe')
head(formatted_probe_positions)

# now attach the data frames
new_cpg_df <- cpg_df %>%
  left_join(formatted_probe_positions, by='probe')
head(new_cpg_df)

```

In the above code, we first obtain the probe names from the betas data frame and then use regular expressions to separate the probe name from the CpG position. Next, we load the Illumina 450k array probe positions and attach them to our *new_cpg_df* data frame.

However, note that the `pos` column from the *Locations* data frame does not match the positions in our `cpg_pos` column. This is because the genomic builds do not match. The *IlluminaHumanMethylation450kanno.ilmn12.hg19* annotations are in the hg19 build, and we are working with hg38 genomic annotations for this analysis. To convert hg19 positions to hg38, we use the *GenomicRanges* and *liftOver* packages. Here's a quick example on how to lift over positions from one build to another. Always ensure that you are working with the correct genome build and that the build matches across all your datasets, or else you will run into big issues!

We need a chain file to lift the genomic positions. The chain file is an annotation file that links the positions between the genome builds. You can download this file from the (UCSC golden path download site)[https://hgdownload.cse.ucsc.edu/goldenpath/hg19/liftOver/]. Be sure to download the file that maps between the appropriate builds. We'll be mapping from hg19 to hg38. We've included the chain used in this analysis as a part of the regionalpcs package, which can be accessed in the "extdata" folder as shown in the code below.

```{r}
# convert hg19 positions into a genomic ranges object

# genomic ranges expects a start and end position so let's add this
hg19_pos <- new_cpg_df %>%
  # select the hg19 positions from the data frame we created
  select('chr', 'pos', 'strand', 'probe') %>%
  # create a start/end column
  mutate(start = pos,
         end = as.numeric(pos)+1)
head(hg19_pos)

# now create the genomic ranges object
hg19_pos_gr <- makeGRangesFromDataFrame(hg19_pos, keep.extra.columns = TRUE)
hg19_pos_gr

# now use liftOver to convert positions to hg38
# load the chain file
chain_file <- system.file("extdata", "hg19toHg38.over.chain", package="regionalpcs")
chain <- import.chain(chain_file)

# liftover
hg38_pos <- liftOver(hg19_pos_gr, chain) %>%
  as.data.frame()
head(hg38_pos)

# let's rename the columns and connect it back with our cpg annotations
formatted_hg38 <- hg38_pos %>%
  select(chrom_hg38 = seqnames, pos_hg38=start, probe)
head(formatted_hg38)

lifted_cpg_df <- new_cpg_df %>%
  left_join(formatted_hg38, by='probe')
head(lifted_cpg_df)

```

With probe positions and genome builds sorted out, we can move on to preprocessing the methylation array data. This usually involves filtering probes with low variability, removing any missing values, and normalizing the beta values. In addition, we may want to perform batch correction or adjust for other sources of technical or biological variation. We'll cover these steps in more detail later in the tutorial. It's important to ensure that our preprocessing steps are appropriate for our research question and dataset, as they can affect downstream analyses and interpretations.


## Process and filter the methylation data.

In this section, we'll remove low variance CpGs and normalize our methylation beta values using the inverse normal transform.

```{r}
# remove low variance cpgs
var_betas <- betas[apply(betas, 1, var, na.rm=TRUE) != 0,] %>%
  na.omit()
dim(var_betas)
```
We are being lenient here and only remove CpGs that have zero variance. However, we can come back and change this threshold later if needed.

Now, let's normalize our methylation values to deal with the heteroscedasticity present in methylation data. We'll apply the inverse normal transform using functions from the **`RNOmni`** package by applying the **`RankNorm`** function to each row of our data frame.

```{r}
# inverse normal transform our methylation beta values
int_meth <- apply(var_betas, 1, RankNorm) %>%
  t() %>%
  as.data.frame()
```

With our filtered and normalized data, we can now summarize region types using the **`regionalpcs`** package.

## Summarizing gene region types

### Loading gene region annotations
We'll start by loading gene region annotations. Make sure that these annotations are using the same genomic reference build (GrCh37, GrCh38) as your CpG annotations. **All annotations included with the *regionalpcs* package are in build hg38.**

```{r}
#  load gene region annotation file
head(gene_annots)
```
The **`gene_annots`** dataset contains annotations for different gene regions, such as promoters, gene bodies, and intergenic regions. 

### Creating a region map

Before summarizing gene regions using **`compute_regional_pcs`**, we need to create a region map that assigns CpGs to gene regions. This map enables us to identify which CpGs fall into each gene region, and the function **`make_region_map`** from the *regionalpcs* package automates this process for us.

To create the region map, we need genomic positions for our CpGs, which we can obtain from the row names of our methylation data frame.


```{r}
head(int_meth)[1:4]

# Get CpG positions from methylation data frame row names
cpg_info = data.frame(cpg_id=rownames(int_meth)) %>%
  # separate info from the cpg ID's
  separate(cpg_id, into=c('chrom', 'start', 'end', 'cpg_name'), sep='_', remove=FALSE)
head(cpg_info)
```


Next, we convert our CpG information and gene region annotations to `GenomicRanges` objects to find the overlaps between the two using `findOverlaps.`

```{r, warning=FALSE}
# Convert CpG info and gene annotations to GenomicRanges objects
cpg_gr <- makeGRangesFromDataFrame(cpg_info, keep.extra.columns = TRUE)
annots_gr <- makeGRangesFromDataFrame(gene_annots, keep.extra.columns = TRUE)

# Find overlaps between the two GRanges objects
overlaps <- findOverlaps(query=cpg_gr, subject=annots_gr) %>%
  as.data.frame()
head(overlaps)

# Match overlaps
matched_cpg <- cpg_gr[overlaps$queryHits,] %>%
  as.data.frame() %>%
  select(cpg_id)

# Select overlapped rows and just keep the columns we need
matched_annots <- annots_gr[overlaps$subjectHits,] %>%
  as.data.frame() %>%
  select(gencode_gene_id)

# Combine the matched CpGs and gene annotations to form the region map
region_map <- cbind(matched_annots, matched_cpg) 
head(region_map)
length(unique(region_map$gencode_gene_id))

```


We can see the resulting region map, which summarizes how our CpGs are assigned to gene regions.


### Summarize gene regions

We'll use the `compute_regional_pcs` function to get regional PCs using default settings. 

```{r}
head(region_map)
sub_region_map <- region_map %>%
  filter(gencode_gene_id %in% unique(region_map$gencode_gene_id)[1:1000])

res <- compute_regional_pcs(int_meth, sub_region_map)
```

The `compute_regional_pcs` function returns a list containing important elements from our regional PC summary method. To understand the output, we can inspect the names of the list elements:

```{r}
names(res)
```

The first element of this list is the regional PCs. These are the summaries for each region contained in the input `region_map.` To select and inspect the regional PCs, we can do the following:

```{r}
# select the regional pcs
regional_pcs <- res$regional_pcs
head(regional_pcs)[1:4]
```
The output is a data frame with regional PCs for each region as rows and our samples as columns. This is our new representation of methylation values, now on a gene regional PC scale. We can feed these into downstream analyses as is.

The number of regional PCs representing each gene region was determined by the Gavish-Donoho method. This method allows us to identify PCs that capture actual signal in our data and not the noise that is inherent in any dataset.

We can check the number of gene regions and regional PCs we have now:


```{r}
# separate the genes from the pc numbers
regions <- data.frame(gene_pc=rownames(regional_pcs)) %>%
  separate(gene_pc, into=c('gene', 'pc'), sep='-')
head(regions)

# number of genes that have been summarized
length(unique(regions$gene))

# how many of each PC did we get
table(regions$pc)
```
We have summarized each of our genes using just one PC. The number of PCs depends on three main factors: the number of samples, the number of CpGs in the gene region, and the noise in the methylation data.

By default, the `compute_regional_pcs` function uses the Gavish-Donoho method. However, we can also use the Marcenko-Pasteur method by setting the `pc_method` parameter:

```{r}
mp_res <- compute_regional_pcs(int_meth, sub_region_map, pc_method='mp')

# select the regional pcs
mp_regional_pcs <- mp_res$regional_pcs

# separate the genes from the pc numbers
mp_regions <- data.frame(gene_pc=rownames(mp_regional_pcs)) %>%
  separate(gene_pc, into=c('gene', 'pc'), sep='-')
head(mp_regions)

# number of genes that have been summarized
length(unique(mp_regions$gene))

# how many of each PC did we get
table(mp_regions$pc)

# multi_genes <- mp_regions %>%
#   filter(pc %in% c('PC2', 'PC3', 'PC4'))
# head(multi_genes)
```

The Marcenko-Pasteur and the Gavish-Donoho methods are both based on Random Matrix Theory, and they aim to identify the number of significant PCs that capture the true signal in the data and not just the noise. However, these methods differ in how they select the number of significant PCs. The Marcenko-Pasteur method typically selects more PCs to represent a gene region compared to the Gavish-Donoho method. This may be due to the different ways in which the two methods estimate the noise level in the data.

Ultimately, the choice between the two methods depends on the specific needs and goals of the analysis. The Gavish-Donoho method tends to provide more conservative results, while the Marcenko-Pasteur method may capture more of the underlying signal in the data. Researchers should carefully consider their objectives and the characteristics of their data when selecting a method.
